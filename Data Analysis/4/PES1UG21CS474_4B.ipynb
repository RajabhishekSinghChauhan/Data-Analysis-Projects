{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Basket Analysis\n",
    "    + Apriori Algorithm\n",
    "    + Association Rule mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "- Revise the following concepts\n",
    "    - Apriori Algorithm\n",
    "        - Suport\n",
    "        - Confidence\n",
    "        - Lift\n",
    "- Install the following software\n",
    "    - pandas\n",
    "    - apyori "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marking scheme\n",
    "1. Problem 1: Preprocessing - 2 marks\n",
    "2. Problem 2: Item set detection and analaysis - 3 marks\n",
    "3. Problem 3: Association rule minning - 5 marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "Welcome to \"FreshEats Superstore\", a budding supermarket. As a data analyst working with \"FreashEats\" , your mission is to uncover meaningful patterns within customer transactions to enhance their shopping experience and help us compete with our competitor \"Not-So-FreshEats\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "- \"FreshEats_transactions.csv\"\n",
    "- Each record of the dataset represents a transaction made by a customer at \"FreashEats Superstore\".\n",
    "- The transaction contains the items bought in that transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.comNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting apyori\n",
      "  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: apyori\n",
      "  Building wheel for apyori (setup.py): started\n",
      "  Building wheel for apyori (setup.py): finished with status 'done'\n",
      "  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5974 sha256=47a56c9eba982ed332ff79fb9e02bb3a474ae2286c983ab55d6c7fd251feda95\n",
      "  Stored in directory: C:\\Users\\sujan\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-2oj2c1dm\\wheels\\77\\3d\\a6\\d317a6fb32be58a602b1e8c6b5d6f31f79322da554cad2a5ea\n",
      "Successfully built apyori\n",
      "Installing collected packages: apyori\n",
      "Successfully installed apyori-1.1.2\n"
     ]
    }
   ],
   "source": [
    "# Install apyori package\n",
    "# Use % or ! based on the environment to install\n",
    "%pip install apyori "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apyori documentation: https://pypi.org/project/apyori/ (Refer API Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 - Preprocessing (2 marks)\n",
    "**Load the transactions data** from the provided csv file. **Transform the data** to a suitable format (Hint: **List of lists**[internal list contains the items of the transaction]). **Make sure to clean the data** (Hint: NA values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataframe\n",
    "df = pd.read_csv(\"74.FreshEats_transactions.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "transactions = []\n",
    "for row in df.iterrows():\n",
    "    items = [item for item in row[1] if not pd.isna(item)]\n",
    "    if items:\n",
    "        transactions.append(items)\n",
    "print(transactions[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 - Item sets (3 marks: 1 + 2)\n",
    "1. Print out the frequent item sets along with their support values also display the count of item sets.(**min_support=0.045**)\n",
    "2. \"FreshEats\" wants to replenish its stocks, help find the top 5 most popular(higher buying frequency) items/item_sets to replenish. Explain and justify the process followed to come to the conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: mlxtend in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from mlxtend) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from mlxtend) (1.24.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from mlxtend) (2.0.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from mlxtend) (1.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from mlxtend) (3.7.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from mlxtend) (1.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sujan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sujan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sujan\\anaconda3\\envs\\project\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sujan\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Item Sets:\n",
      "   support    itemsets\n",
      "0      1.0       (1.0)\n",
      "1      1.0       (0.0)\n",
      "2      1.0  (0.0, 1.0)\n",
      "Count of Frequent Item Sets: 3\n",
      "Top 5 Most Popular Items/Item Sets:\n",
      "   support    itemsets\n",
      "0      1.0       (1.0)\n",
      "1      1.0       (0.0)\n",
      "2      1.0  (0.0, 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujan\\anaconda3\\envs\\Project\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "all_items = set(item for transaction in transactions for item in transaction)\n",
    "all_items = list(all_items)\n",
    "transaction_dicts = []\n",
    "\n",
    "for transaction in transactions:\n",
    "    transaction_dict = {item: 1 for item in transaction}\n",
    "    transaction_dicts.append(transaction_dict)\n",
    "df = pd.DataFrame(transaction_dicts)\n",
    "df = df.fillna(0)\n",
    "\n",
    "frequent_item_sets = apriori(df, min_support=0.045, use_colnames=True)\n",
    "\n",
    "# Count the number of frequent item sets\n",
    "num_frequent_item_sets = frequent_item_sets.shape[0]\n",
    "sorted_frequent_item_sets = frequent_item_sets.sort_values(by='support', ascending=False)\n",
    "\n",
    "top_5_popular_item_sets = sorted_frequent_item_sets.head(5)\n",
    "\n",
    "print(\"Frequent Item Sets:\")\n",
    "print(sorted_frequent_item_sets)\n",
    "\n",
    "print(\"Count of Frequent Item Sets:\", num_frequent_item_sets)\n",
    "\n",
    "print(\"Top 5 Most Popular Items/Item Sets:\")\n",
    "print(top_5_popular_item_sets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 - Association Rules (5 marks: 1 + 2 + 2)\n",
    "+ Items on the left side of the association rule are called : **Antecedent items** and the right side of the association rule are called : **Consequent Items**.\n",
    "1. Print out the association rules along with their confidence and lift. (Analyse the output structure of apriori())\n",
    "    + **(min_support=0.01, min_confidence = 0.045, min_lift=1.5, min_length=2)**\n",
    "2. As the Holiday season is approaching, \"FreshEats\" is considering to provide discounts and offers on some of their products. Help them identify the top 5 popular **pairs/sets** of items/item_sets bought, considering probability of consequent item being purchased when antecedent item is bought.\n",
    "3. Also help them identify the top 5 popular **pairs/sets** of items/item_sets bought together, considering the popularity of consequent and antecedent items.\n",
    "+ (Consequent and antecedent items together form the **pairs/sets** specified in the question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association Rules with Confidence and Lift:\n",
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0       (0.0)       (1.0)                 1.0                 1.0      1.0   \n",
      "1       (1.0)       (0.0)                 1.0                 1.0      1.0   \n",
      "\n",
      "   confidence  lift  leverage  conviction  zhangs_metric  \n",
      "0         1.0   1.0       0.0         inf            0.0  \n",
      "1         1.0   1.0       0.0         inf            0.0  \n",
      "Top 5 Popular Pairs/Sets of Items/Item Sets (Confidence-based):\n",
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0       (0.0)       (1.0)                 1.0                 1.0      1.0   \n",
      "1       (1.0)       (0.0)                 1.0                 1.0      1.0   \n",
      "\n",
      "   confidence  lift  leverage  conviction  zhangs_metric  \n",
      "0         1.0   1.0       0.0         inf            0.0  \n",
      "1         1.0   1.0       0.0         inf            0.0  \n",
      "Top 5 Popular Pairs/Sets of Items/Item Sets (Popularity-based):\n",
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0       (0.0)       (1.0)                 1.0                 1.0      1.0   \n",
      "1       (1.0)       (0.0)                 1.0                 1.0      1.0   \n",
      "\n",
      "   confidence  lift  leverage  conviction  zhangs_metric  item_support  \\\n",
      "0         1.0   1.0       0.0         inf            0.0           1.0   \n",
      "1         1.0   1.0       0.0         inf            0.0           1.0   \n",
      "\n",
      "   antecedent_support  popularity  \n",
      "0                 1.0         1.0  \n",
      "1                 1.0         1.0  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "association_rules_df = association_rules(frequent_item_sets, metric=\"confidence\", min_threshold=0.045)\n",
    "\n",
    "sorted_association_rules = association_rules_df.sort_values(by='confidence', ascending=False)\n",
    "\n",
    "print(\"Association Rules with Confidence and Lift:\")\n",
    "print(sorted_association_rules)\n",
    "\n",
    "top_5_popular_pairs = sorted_association_rules.head(5)\n",
    "\n",
    "print(\"Top 5 Popular Pairs/Sets of Items/Item Sets (Confidence-based):\")\n",
    "print(top_5_popular_pairs)\n",
    "\n",
    "sorted_association_rules['item_support'] = sorted_association_rules['consequents'].apply(lambda x: frequent_item_sets.loc[frequent_item_sets['itemsets'] == x].iloc[0]['support'])\n",
    "\n",
    "sorted_association_rules['antecedent_support'] = sorted_association_rules['antecedents'].apply(lambda x: frequent_item_sets.loc[frequent_item_sets['itemsets'] == x].iloc[0]['support'])\n",
    "\n",
    "sorted_association_rules['popularity'] = sorted_association_rules['item_support'] * sorted_association_rules['antecedent_support']\n",
    "\n",
    "sorted_association_rules = sorted_association_rules.sort_values(by='popularity', ascending=False)\n",
    "\n",
    "top_5_popular_pairs_popularity = sorted_association_rules.head(5)\n",
    "\n",
    "print(\"Top 5 Popular Pairs/Sets of Items/Item Sets (Popularity-based):\")\n",
    "print(top_5_popular_pairs_popularity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
